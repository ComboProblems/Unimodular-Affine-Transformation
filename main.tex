\documentclass{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,mathabx,biblatex}
\usepackage{tikz-cd}
\usepackage{geometry}
\geometry{ margin=1.25in}
\linespread{1.2}
\renewcommand\qedsymbol{$\blacksquare$}
%-----------------------------------------------------------------------------------------
%-------AESTHETIC CHANGES:
\newcommand{\nl}{\bigskip \\ } %New Line with space. 
  \renewcommand{\leq}{\leqslant}
  \renewcommand{\geq}{\geqslant}
%-----------------------------------------------------------------------------------------
%-------ABBREVIATIONS:
  \newcommand{\es}[0]{\emptyset}		%  empty set.
  \newcommand{\se}[0]{\subseteq}		%  subset or equal.
  \newcommand{\ps}[0]{\subset}			%  proper subset.
%-----------------------------------------------------------------------------------------
%-------SETS OF NUMBERS:
  \newcommand{\N}[0]{\mathbb{N}}		%  Natural ##s
  \newcommand{\Z}[0]{\mathbb{Z}}		%  Integer ##s
  \newcommand{\Q}[0]{\mathbb{Q}}		%  Rational ##s
  \newcommand{\R}[0]{\mathbb{R}}		%  Real ##s
  \newcommand{\ER}[0]{\overline{\mathbb{R}}}	%  Extended Real ##s
  \newcommand{\C}[0]{\mathbb{C}}		%  Complex ##s
  \newcommand{\EC}[0]{\overline{\mathbb{C}}}	%  Extended Complex ##s
  \newcommand{\SP}[0]{\mathbb{S}}		%  Sphere
  \newcommand{\So}[0]{\SP^1}			%  1-Sphere
  \newcommand{\Sm}[0]{\mathcal S}
  \newcommand{\La}[0]{\mathcal L}
  \newcommand{\im}[0]{\text{im}}
%-----------------------------------------------------------------------------------------
%-------LOGICAL STATEMENTS:
  \newcommand{\fa}[1]{\(\forall\,#1\,\)}	%  for all ...
  \newcommand{\te}[1]{\(\exists\,#1\,\)}	%  there exists	...
  \newcommand{\then}[0]{\Longrightarrow}	%  then ...
%  \newcommand{\iff}[0]{\Longleftrightarrow}	%  if and only if ...
%-----------------------------------------------------------------------------------------

\newcommand{\gen}[1]{\langle #1 \rangle} %brackeded generator 
  \newcommand{\abs}[1]{\left\lvert#1\right\rvert}	%  Absolute Value |.|
  \newcommand{\abst}[1]{\lvert#1\rvert}			%  Absolute Value (text)
  \newcommand{\norm}[1]{\left\|#1\right\|}		%  Norm ||.||
  \newcommand{\ip}[2]{\left\langle#1,#2\right\rangle}	%  Inner Product <.,.>
  \newcommand{\ipt}[2]{\langle#1,#2\rangle}		%  Inner Product (text)
  \newcommand{\ipn}[1]{\left\langle#1,#1\right\rangle}  %  Inner Product Norm
  \newcommand{\de}[2]{\frac{d#1}{d#2}}			%  Diff.
  \newcommand{\nde}[3]{\frac{d^{#3}#1}{d#2^{#3}}} 
	%  nth order diff.
  \newcommand{\der}[1]{\frac{d}{d#1}}			%  Der.
  \newcommand{\des}[2]{\frac{d^2#1}{d#2^2}}		%  2nd order diff.
  \newcommand{\pde}[2]{\frac{\partial#1}{\partial#2}}	%  p. diff.
  \newcommand{\pdes}[2]{\frac{\partial^2#1}{\partial#2^2}}  %  2nd Order P. Diff.
  \newcommand{\npde}[3]{\frac{\partial^{#3}#1}{\partial#2^{#3}}}  %  nth Order P. Diff.
  \newcommand{\tpde}[3]{\frac{\partial^2#1}{\partial#2\,\partial#3}}  %  2* P.Der.
  \newcommand{\pder}[1]{\pde{}{#1}}			%  Partial Derivative
  \newcommand{\pders}[1]{\pdes{}{#1}}			%  Partial Derivative
  \newcommand{\tpder}[2]{\tpde{}{#1}{#2}}		%  2* Partial Derivative
  \newcommand{\defct}[3]{#1:#2\rightarrow#3}		%  Function Definition
% A couple of notes on these definitions, those with a `t' appended to
% the end are intended for use in the short math expression environments
% they get rid of the enlarging of the delimiters and make everything
% nice and compact.
%	DOCUMENT SPECIFIC NOTATION:
\newcommand{\T}{\mathcal T}		%  Tangential unit vector
  \newcommand{\B}[0]{\hat{B}}		%  Torsional unit vector
  \newcommand{\e}[1]{\hat{e}_{#1}}
  \newcommand{\X}[0]{\mathcal{X}}
  \newcommand{\y}[0]{\mathcal{y}}
    \newcommand{\per}[1]{\left(#1\right)}
  \newcommand{\D}[0]{\mathrm{D}}
  \newcommand{\LL}[0]{\mathrm{L}}
%	FORMATING:
%  \renewcommand{\qedsymbol}{\(\bigstar\)}	%  Cuter Q.E.D.
  \renewcommand{\labelenumi}{(\roman{enumi})}	%  Roman numberals good
    \newtheorem{thm}{Theorem}[section]
    \newtheorem{lem}[thm]{Lemma}
    \newtheorem{cor}[thm]{Corollary}
    \newtheorem{prop}[thm]{Proposition}
    \newtheorem{ex}[thm]{Example}
    \newtheorem{conj}[thm]{Conjecture}
  \theoremstyle{definition}
    \newtheorem{defn}[thm]{Definition}
    \newtheorem*{T0}{\(T_0\) Axiom}
    \newtheorem*{T1}{\(T_1\) Axiom}
    \newtheorem*{T2}{\(T_2\) Axiom}
    \newtheorem*{T3}{\(T_3\) Axiom}
    \newtheorem*{T35}{\(T_{3\frac{1}{2}}\) Axiom}
    \newtheorem*{T4}{\(T_4\) Axiom}
  \theoremstyle{remark}
    \newtheorem{rem}[thm]{Remark}
  \newcommand{\rlem}[1]{Lemma~\ref{#1}}
  \newcommand{\rlems}[2]{Lemmas~\ref{#1} \& \ref{#2}}
  \newcommand{\rrem}[1]{Remark~\ref{#1}}
  \newcommand{\rprop}[1]{Proposition~\ref{#1}}
  \newcommand{\rprops}[2]{Propositions~\ref{#1} \& \ref{#2}}
  \newcommand{\rthm}[1]{Theorem~\ref{#1}}
  \newcommand{\rdef}[1]{Definition~\ref{#1}}
  \newcommand{\refig}[1]{Figure~\ref{#1}}
  \newcommand{\rfig}[1]{Figure~\ref{#1}}
  \newcommand{\rcor}[1]{Corollary~\ref{#1}}
  \newcommand{\requ}[1]{Equation~\ref{#1}}
  \newcommand{\rpage}[1]{p.~\pageref{#1}}
\newcommand{\tensor}{\otimes}
%	MISC.:
  \newcommand{\topol}[0]{\mathcal{T}}

%	MEASURE THEORIC NOTATIONS:
  \newcommand{\sig}[1]{\(\sigma\)-#1}			% sigma-...
  \newcommand{\co}[0]{\mathcal{E}}			% arbitrary class of sets.
  \newcommand{\ri}[0]{\mathcal{R}}			% arbitrary ring.
  \newcommand{\sr}[0]{\mathcal{S}}			% arbitrary sigma ring.
  \newcommand{\sa}[0]{\mathfrak{M}}			% arbitrary sigma algebra.
  \newcommand{\hc}[0]{\mathcal{H}}			% arbitrary hereditary class.
  \newcommand{\di}[2]{\int#1\,d#2}			% integral of 1 wrt 2.
  \newcommand{\io}[3]{\int_#1#2\,d#3}			% integral of 2 wrt 3 over 1.
%  \usepackage{quiver}
 \addbibresource{ref.bib}

\title{Unimodular Affine Transformation}
\author{Acadia Larsen}
\begin{document}
\maketitle
\textcolor{red}{Text in red is questions/things i'm not sure about}\nl 
\textcolor{blue}{text in blue is things I am going to change and have written for my own edification.}
\section{Preliminaries for Lattices and Rational Vector Spaces }
Though out, let $V$ be a $m$ dimensional real vector space. 
 \begin{defn}
 
A \textbf{lattice} $\Lambda$ is a subset of $\R^m$ which is an additive Abelian subgroup under standard vector addition with the condition there are $k$ linearly independent vectors $b_1,...,b_k$ where $\Lambda = \left\{\sum\limits_{i=1}^k \lambda_i b_i : \lambda_i \in \Z\right\}$. The vectors $b_1,...,b_k$ for a basis for the lattice. 
 \end{defn}
 When the number of basis vectors of a lattice is the same as the dimension of the ambient space $V$, we say that the lattice $\Lambda$ is full rank in $V$.  We write $\Lambda = \La(B)$ to denote a lattice with a basis $B = \{b_1,...,b_n\}$. A lattice is topologically discrete meaning that it has the finest topology which in which singletons are opens sets. 

A \textbf{rational vector space} $V$ of dimension $m$ is a finite dimensional real vector space with a lattice denoted by $\Lambda$ where $\Lambda$ is full rank in $V$. An element $v\in V$ is called \textbf{rational} if $nv\in \Lambda$ for $n\in \Z^+$. We say a subspace $L$ of $V$ is called \textbf{rational} if $L\cap \Lambda$ is a full rank lattice in $L$. The image of $\Lambda$ in $V /L$ is called the \textbf{projected lattice}.\cite{Baldoni_2012} \nl 

Our goal is to given a direct decomposition of $V$, the ambient space, into a rational vector space $L$ with lattice $\Lambda$ with a direct sum complement $M$, find an affine transformation that is lattice preserving for $L$ and, depending on other options, arbitrary/orthogonal/orthonormal for $M$. In this context, $L$, $\Lambda$, and $V$ are data of the problem.  \nl 

The lattice $\Lambda$ determines the subspace $L$ and is sufficient input for the problem. Setting $L  =\text{span}_\R(\Lambda)$, this holds because $L$ is assumed to be a rational vector space, we need $L\cap \Lambda$ to be full rank in $L$ which means that $\Lambda$ has the dimension of $L$ basis vectors and hence also spans $L$. The dimension of the ambient vector space can be determined by the input data.  Therefore only a lattice is needed as data to the problem. \nl 

\textbf{Process Outline:}\nl
\textbf{Step 1.} The user gives data (a lattice $\Lambda$) to the function.  Either as a basis of a lattice or arising from as the integer kernel from a linear system, $\Lambda = \{x\in \Z^n: Ax=0\}$ for some $m\times n$ matrix $A$. \nl 
\indent \textit{Processing data}\nl 
When processing the data, we wish to accept two forms of data of the problem. The first form is a lattice basis form and the second is a matrix form. The lattice basis or matrix form comes in two flavors; a integral (rational) form and a mixed integer case. \nl 
\indent \textit{Case 1a:} The lattice is specified by a collection of $N$ rational vectors $B= \{b_1,...,b_N\}$ in the lattice with the possibility of $N\geq m$. One can compute the Hermite Normal Form of $B =(b_1,...,b_N)$ to give a basis of the lattice.\nl
\indent \textit{Case 1b:} The lattice is specified by a collection of $N$ vectors $B= \{b_1,...,b_N\}$ in the lattice with the possibility of $N\geq m$. {\color{red} We will show that this is a special case of case 2.}\nl 

\indent \textit{Case 2:} The lattice is specified by as the integer kernel from a linear system of equations i.e. $\Lambda = \{x\in \Z^n: Ax=0\}$ for some $m\times n$ matrix $A$.
Depending on the smallest subfield of $\R$ that the entereis in $A$ are, there are different approaches for finding a lattice basis here. \nl  
{\color{red} \indent \textit{Case 3:} The lattice is specified as integer kernel of the affine hull of a polytope. Since the affine hull of a polytope is given by it's equations being 0, we can reduce this case to case 2. }\nl 

Now we can assume we have a basis $B= \{b_1,...,b_k\}$ of the rational space $L = \text{span}_\R(\Lambda)$ with $\Lambda = \La(B)$. \nl 
\textbf{Step 2.} Complete a basis of $V$. That is find a basis of $M\cong V/L$ say $b_{k+1},..., b_{m}$ with the vectors having user specified properties. The user can chose the basis to be arbitrary, orthogonal, orthonormal to with respect to each other, $L$, or $\Lambda$ as appropriate.  
\nl 
\textbf{Step 3.} Define the map $T$ as $T = (b_1,...,b_k,b_{k+1},...b_m)$. Return this as a matrix.  \nl 




\section{Computing Cases 1b/2/3 in step 1}
\subsection{Computing $\ker_\Z(A)$ for $A$ with rational entries}

\begin{defn}
A unimodular matrix $U$ is a square matrix with integer entries and $\det(U)=\pm 1$. %(I.e $U\in GL_n(\Z)$) 
\end{defn}
An important form of integral linear transformations is the Hermite normal form. 
\begin{defn}
The Hermite normal form of a matrix $A\in\Z^{m\times n}$ is a matrix $H$ with a $m\times m$ lower triangular matrix $D$ with strictly positive entries such that $AU = H = (D~0)$ where $U$ is a $n\times n$ unimodular matrix.
\end{defn}
\begin{lem}
If $A$ is an integral $m\times n$ matrix and $U$ is a $n\times n$ unimodular matrix, then $\La(AU) = \La(A)$. 
\end{lem}
{\color{blue}Polish --  
\begin{proof}
 Since $Ux = w$ where $w\in \Z^n$ and that $U$ is unimodular, we know that $U^{-1}$ is also unimodular, so $x = U^{-1}w$. By this fact $\La(A) = \{Ax :x\in \Z^n\} = \{AU U^{-1}w : U^{-1}w\in \Z^n \} =\{AU x : x\in \Z^n \} =\La(AU)$. 
 \end{proof}}
\begin{prop}
\begin{itemize}
    \item Interchanging columns, adding column two columns $i$ and $j$, or multiplying a column by $-1$ can be expressed by multiplication of $A$ by unimodular matrix. 
    \item The product of unimodular matrices is a unimodular. 
\end{itemize}
\end{prop}
The proof could be left as an exercise or by reference. The interesting part is being able write down the column operations. These are simply done by modifying the identity matrix and using the properties of determinants to show that the determinate is as needed. 
\begin{thm}\label{HNF}
If $A$ is an $m\times n$ integer matrix with rank $A$ being $m$, then $A$ has a Hermite normal form and $D^{-1}A$ is an integer matrix. 
\end{thm}
\begin{proof}
\textit{Sketch.}
We describe an algorithm to compute the Hermite normal form of $A$. {\color{blue} Figure out how you like to write this proof and complete it.} 
\end{proof}
{\color{red} When $A$ has rank $k<m$, the idea is to reduce the problem to the full rank case. This can be done by defining a projection operator which is one to one on the restriction and has an easy to compute inverse. To do is to write this out properly and double check the details. }

\begin{rem}
There is polynomial time algorithm to compute the Hermite Normal form of matrix $A$ with integral entries. \cite{KoppeJesusBook} 
\end{rem}
\begin{thm}\label{LatticeBasis}
Suppose that $A:\R^m\to \R^n$ is a linear transformation with integral entries, then the last $n-d$ columns of $U$ in the Hermite Normal form of $A$ generate $\ker_\Z (A) =\{ x\in \Z^n: Ax = 0\}$ where $d$ is the dimension of $\ker(A)$.  
\end{thm}
\begin{proof}

 Suppose we have computed the Hermite normal form, that is $AU = H$. Let $u_i$ be one of the last $d$ columns of $U$, noting that the entries of $u_i$ are integral. Then $Au_i = 0$ by this decomposition and so $u_i\in \ker_{\Z}(A)$. Let $y = U^{-1}z$ with $z\in \ker_{\Z}(A)$, we have that $AUy = AUU^{-1}z = Az = \vec{0} = (D~0)y$. So we have that $D^{-1}AUy = (I~0)y =\vec{0}$. This implies that $y = \sum\limits_{i=d+1}^n y_ie_i$ where $e_i$ is a standard basis vector. Thus $U^{-1}z =\sum\limits_{i=d+1}^n y_ie_i  $ implies $z  =\sum\limits_{i=d+1}^n y_iUe_i =\sum\limits_{i=d+1}^n y_iu_i   $ hence the last $d$ columns of $U$ form a basis of $\ker_{\Z^m}(A). $ 

\end{proof}



\begin{prop}
Let $A:\R^m \to \R^n$ be an integral linear transformation. $\ker_\Z(A) \cap \Lambda$ can be computed by computing the Hermitian Normal form of the dual of $\ker_\Z(A) \cap \Lambda$.
\end{prop}
\begin{proof}
We can commute the dual basis of $\ker_Z(A)$ and $\Lambda$. Let $B$ be the lattice basis of $\ker_\Z(A)$ and $B'$ be the lattice basis of $\Lambda$ with dual basis $C$ and $C'$ respectively.   The lattices of $\La(B)$ and $\La(B')$, then the dual of $\La(B)\cap \La(B')$ is $\La([C|C'])$. This can be checked by a similar argument to Theorem \ref{DualLattice}. Then basis for $\La(B)\cap \La(B')$ can be computed via Theorem \ref{LatticeBasis} using the matrix $[C|C']$ and taking the dual of that. 
\end{proof}



\subsection{Computing $\ker_\Z(A)$ for $A$ with algebraic entries}

\begin{ex}\label{DimDiff}
Let $A = \begin{bmatrix}1+\sqrt{2} & 0 & 1+\sqrt{2} & \sqrt{3} \\ 0 & 1 & -1 &1\end{bmatrix}$. Then $\ker_\Z(A) = \left\{n\begin{pmatrix} 1\\ -1\\ 1\\ 0\end{pmatrix}: n\in \Z\right\}$. 
\end{ex}
\begin{proof}
First, $\Q(\sqrt{2},\sqrt{3})\subset \R$ is a  4 dimensional $\Q$ vector space with basis elements $1,\sqrt{2},\sqrt{3},\sqrt{6}$. For any $x\in \Q(\sqrt{2},\sqrt{3})$, there are rational numbers $q_1,q_2,q_3,q_4$ such that $q_1+q_2\sqrt{2} +q_3\sqrt{3} +q_4\sqrt{6} = \begin{pmatrix}1& \sqrt{2} & \sqrt{3} & \sqrt{6} \end{pmatrix}\begin{pmatrix} q_1\\ q_2\\q_3\\q_4\end{pmatrix}$.  Let $\vec{\alpha} = \begin{pmatrix}1& \sqrt{2} & \sqrt{3} & \sqrt{6} \end{pmatrix}$. Then $Ax = 0$ with $x\in \Q^4$, gives two equations $(1+\sqrt{2}) x_1 + 0 x_2 + (1+\sqrt{2}) x_3 + \sqrt{3}x_4 = 0$ and  $0x_1 + 1 x_2 + - x_3 + 1x_4 = 0$. The first equation in $\Q(\sqrt{2},\sqrt{3})$ is \begin{align}
    (1+\sqrt{2}) x_1 + 0 x_2 + (1+\sqrt{2}) x_3 + \sqrt{3}x_4 &= 0\\ 
     \begin{pmatrix}1\\1\\0\\0\end{pmatrix} x_1 +\begin{pmatrix}0\\1\\0\\0\end{pmatrix} x_2+  \begin{pmatrix}1\\-1\\0\\0\end{pmatrix} x_3+  \begin{pmatrix}0\\1\\1\\0\end{pmatrix} x_4& =\begin{pmatrix}0\\0\\0\\0\end{pmatrix} \\ 
    \begin{pmatrix}1&0&1&0\\1&1&-1&1\\0&0&1&0\\0&0&0&0\end{pmatrix} x =\begin{pmatrix}0\\0\\0\\0\end{pmatrix} . 
\end{align} A similar matrix equation holds for the other equation seeing that \begin{equation}\begin{pmatrix}0&1&-1&1\\0&0&0&0\\1&0&0&0\\0&0&0&0\end{pmatrix} x =\begin{pmatrix}0\\0\\0\\0\end{pmatrix}. \end{equation} As the $x$ vector is the same in both cases we can write this as a single matrix equation \begin{equation}\label{Ex2}
    \begin{pmatrix}1&0&1&0\\1&1&-1&1\\0&0&1&0\\0&0&0&0\\0&1&-1&1\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix} x=\begin{pmatrix}0\\0\\0\\0\\0\\0\\0\\0\end{pmatrix}. 
\end{equation} 
So solving $Ax=0$ for $x\in \Q^4$ is equivalent to solving the equation in line (\ref{Ex2}). This can be done with any method to solve matrix equations over a field. Take for instance Gram-Schmidt or LU-Factorization. Solving this matrix equation, we conclude that $x\in \text{span}\left\{\begin{pmatrix} 1\\ -1\\ 1\\ 0\end{pmatrix}\right\} $ in $\Q^4$. Picking $x$ such that $x\in \Z^4$, we arrive at the desired conclusion. 
\end{proof}
\begin{thm}\label{AlgebraicEnteries}
Suppose that $A$ is an $m\times n$ matrix each entry being algebraic over $\Q$. \textcolor{blue}{Then $\ker_\Z(A)$ can be computed by an equivalent rational matrix problem. }
\end{thm}
\begin{proof} 
We have that $\{x\in \Z^n : Ax = 0\} \subset \{x\in \Q^n : Ax =0\}$. There is an $a\in \Z$ such that for any  $x\in \Q^n$, $ax \in \Z^n$. Therefore if $x\in \Q^n$ and $Ax =0$, then $ax\in Z^n$ and $A(ax) = 0$. So computing $\ker_\Q(A)$ gives $\ker_\Z(A)$ too. 

Next, all the entries $a_{ij}$ of $A$ are algebraic over $\Q$, there is a polynomial such that $p(x)$ such that $p(\alpha_{ij}) \in \Q$. Let $m(x)$ be the minimal polynomial such that if $\alpha$ is a root of $p(x)$ then $\alpha$ is a root of $m(x)$. Then let $\Q(\alpha)$ be the splitting field of $m(x)$. This is a field extension of $\Q$ of degree $d$ where $d$ is the degree $m(x)$. Such a field extension of $\Q$ is a $d$ dimensional $\Q$ vector space with basis $1,\alpha_1,\dots,\alpha_{d-1}$ letting $\vec{\alpha}^T = (1,\alpha_1,...,\alpha_{d-1})$ where $\alpha_i$ are the distinct roots of $m(x)$. Then for $y\in \Q(\alpha)$, we have $y =\vec{\alpha}^T \begin{pmatrix}
y_1\\ y_2\\ \vdots \\ y_d 
\end{pmatrix} = \vec{\alpha}^T \vec{y}$. In particular for entries $a_{ij} $ in $A$, we can express the entry as  $a_{ij}=\vec{\alpha}^T \vec{a_{ij}} $

Now computing $Ax =0$ for $x\in \Q^n$. For $1\leq i\leq m$, $Ax=0$ implies \begin{equation}
    \sum_{j=1}^m a_{ij} x_i = \sum_{j=1}^m \vec{\alpha}^T \vec{a_{ij}} x_i  = \vec{\alpha}^T\sum_{j=1}^m  \vec{a_{ij}} x_i  =\vec{\alpha}^T \vec{0}.
\end{equation} We can use left cancellation and then solve the equivalent problem \begin{equation}
     \sum_{j=1}^m \vec{a_{ij}} x_i = \begin{bmatrix} \vec{a_{i1}} & \vec{a_{i2}} & \cdots & \vec{a_{in}} \end{bmatrix} x=  \vec{0}.
\end{equation}  Let $\vec{A}$ be the matrix with entry $ij$ being $\vec{a_{ij}}$. Then solving   $\vec{A} x  =  \begin{pmatrix}\vec{0} \\ \vdots \\ \vec{0}
\end{pmatrix}$ with $x\in \Q^n$ gives a solution to the original problem of $Ax = 0$ with $x\in\Z^n$. The problem  $\vec A x = 0$ can be solved by any number of matrix solving algorithms. Therefore finding $\ker_\Q(\vec{A})$ gives $\ker_\Z(A).$


\end{proof}
\textcolor{blue}{From 11.10.2022, I will worry about making the statement of Theorem \ref{AlgebraicEnteries} precise later.}


\subsection{Aribtary Real Data}
\textcolor{blue}{TBD}
\begin{conj}
    Let $A$ be a real $m\times n$ matrix. If $\ker_\Z(A)$  is non-trivial, then $\ker_\Z(A)$ can be deterimed in finite time. 
\end{conj}
%if you had enough time 
\section{Structure of $\ker_\Z(A)$ with real data}
\subsection{Lattices of Full Rank}

% \begin{prop}
% If $A$ has rational entries, then $\ker_\Z(A)$ is a full rank lattice.
% \end{prop}
% \begin{proof}
% This follows from computing the Hermite Normal form of $A$. This immediately gives that $dim(\ker_\Z(A)) = n-m = dim(\ker_\R(A))$. 
% \end{proof}

%\begin{thm}
%$\Lambda$ is a full rank lattice if and only if $\tilde \Lambda$ is a full rank lattice. 
%\end{thm}
%This should follows from Theorem 4.2 and prop 4.3. 
\subsection{Difference in dimension}
In the case where the data is rational, $dim(\ker_\Z(A)) = dim(\ker_\R(A))$. Notice in Example \ref{DimDiff} that $dim(\ker_\R(A))=2$ but $dim(\ker_\Z(A))=1$. What causes this difference in dimension?  The answer lies in the dual of the $\ker_\Z(A)$ as a $\Z$-module. 
\begin{defn}
The \textcolor{red}{ dual of a lattice $\Lambda$ as a $\Z$-module} is the set $\Lambda^\vee = \{ z: z^Tx \in \Z ,\forall x \in \Lambda\} $. \textcolor{red}{I haven't checked the details on this thoroughly, i.e. revisited textbooks ect} %Should this be the correct language here? I think so because this should be the space of linear functionals on $\Lambda$ which preserve the $\Z$-module property. I have not double checked defintions
\end{defn}
%Here the span of the basis vectors lie in $\R^n$. It is possible that there is a sequence $(y_n)\subseteq \tilde \Lambda$ that converges in the Eulcidan metric in $\R^n$. If such a sequence exists, then $\tilde \Lambda$ would not be a lattice because $(y_n)\to y$ and $y$ would not be an isolated point.  Furthermore, $(y_n)^Tx \in\Z $
%for all $ x\in \Lambda$ so $y^Tx \in \Z$ (strongly convergence implies weak convergence). We would $y \in \tilde{\Lambda}$. There is a trick that we can use in terms of formulating the problem to help insure that $y\in \tilde \Lambda$ which we will see in the form of an example.  %This means that $y\in \tilde{\Lambda}$ as $y \in span_\Z(\Lambda)$ by convergence. % \begin{thm}
% A lattice $\Lambda$ is full rank if and only if $\tilde \Lambda$ is full rank. 
% \end{thm}
% \begin{proof}
% ($\implies$) Suppose that $\Lamdda$ is a full rank lattice. 
% \end{proof}



% In Example \ref{DimDiff}, $\Lambda= \ker_\Z(A)$ is not a full rank lattice as since $dim(\ker_\Z(A)) < dim(\ker_\R(A))$. In the dual of $\Lambda$ as a $\Z$ module, there is a point which is not isolated meaning that the  the rowspan of $A$ is dense in some subspace of $\R^4$. This density means that the topological properties of a lattice are no longer satisfied. In the following example, we shall explicit show the violation that in the lattice dual, there is a subspace that is dense in $\R^4$ 

\begin{ex}
Let $A = \begin{bmatrix}1+\sqrt{2} & 0 & 1+\sqrt{2} & \sqrt{3} \\ 0 & 1 & -1 &1\end{bmatrix}$. Define $\hat A = \begin{pmatrix}
A \\ I_4
 \end{pmatrix}$. We claim that $ \ker_\Z(A)^\vee$ is not a lattice. %\begin{itemize}
\end{ex}
\begin{proof}

We will find a infinite sequence $(z^{(n)})_{n=1}^\infty$ with $z^{(n)}\in \Z^6$ such that $z^{(n)}\hat A$ converges with respect to the Euclidean norm and $z^{(n)}$ is distinct form $z^{(m)}$ provided $m\neq n$. This will imply that $\lim_{n\to \infty} \hat A^T z^{(n)} = y \in rowspan_\R(A)$. By adding the guarantee that $z^{(n)}\hat A^Tx =0$ for all $x\in \ker_\Z(A)$, this guarantees that $y^Tx=0$, so $y\in \ker_\Z(A)^\vee$. Finding such a $y$ gives that $y$ is not isolated in the $rowspan_\R(A)$ meaning that $ \ker_\Z(A)^\vee$ cannot be a lattice.  
We start by computing $\hat A^Tz$ for $z\in \Z^6$,
\begin{align}
    \begin{bmatrix}
    1+\sqrt{2} &0 & 1& 0 &0&0 \\ 
    0 &1 & 0& 1 &0&0 \\
    1+\sqrt{2} &-1 & 0& 0 &1&0 \\
    \sqrt{3} &1 & 0& 0 &0&1 
    \end{bmatrix}\begin{pmatrix}
    z_1\\z_2\\z_3\\z_4\\z_5\\z_6
    \end{pmatrix}&= \begin{pmatrix}
    (1+\sqrt{2})z_1 +z_3 \\ 
    z_2 +z_4\\
     (1+\sqrt{2})z_1 -z_2+z_5 \\
          \sqrt{3}z_1 +z_2+z_6
    \end{pmatrix}=y.
\end{align}
Consider the sequences of convergents of the partial fraction decomposition of $1+\sqrt{2}$. Define these as $\{\frac{p_n}{q_n}\}_{n=1}^\infty$. Because this is a sequence of convertenets, it gives the bound $|(1+\sqrt{2})q_n - p_n|< \frac{1}{q_n}$. 
We can pick a sequence of integers $r_n$ such that $|\sqrt{3}q_n -r_n|<1$. Now  define $z^{(n)} = \begin{pmatrix}
q_n & 1& -p_n & 1 & -p_n+1 & -r_n-1 
\end{pmatrix}^T.$ 


 Computing the norm, $$||\hat A^T z^{(n)}||^2 = ||(z^{(n)})^T\hat A||^2 = ((1+\sqrt{2})q_n - p_n)^2 + (1-1)^2 +(1+\sqrt{2})q_n - 1- p_n+1)^2 + (\sqrt{3}q_n +1-r_n-1)^2< 2q_n^{-2}+1.$$  Thus the sequence of norms is bounded above by $3$ because $|q_n|\geq 1$. We also know that because $1+\sqrt{2}$ and $\sqrt{3}$ are irrational,  $0<|(1+\sqrt{2})q_n - p_n|$ and $0<|\sqrt{3}q_n -r_n| $. So $0<||A^Tz^{(n)}||^2 < 2q_n^{-2}+1\leq 3$ is a bounded sequence. Because of this boundedness, there is a convergent subsequence of $A^Tz^(n)$ say $A^Tz^{(n)_k}=y_k \to y$. 

Notice since $\ker_\Z(A) = \{ n\begin{pmatrix}
1 & -1 &1 &0
\end{pmatrix}^T:n\in \Z\}$ that $y_k^Tx =0$ by our choice of $z^{(n)}$. Because $rowspan_\R(A)$ is a closed set with respect to the educlidan norm, $y\in rowspan_\R(A)$ and too $y^Tx =0$. Lastly, we note by choosing a sequence of convergents it follows that $|(1+\sqrt{2})q_n +p_n|>|(1+\sqrt{2})q_{n+1} +p_{n+1}|$ for all $n$. This ensures that the sequence $y_k$ consists of distinct elements. 
Now for any $\epsilon>0$, the open ball of radius $\epsilon$ about $y$ $B_\epsilon(y)$ has an infinitely distinct points in $\ker_\Z(A)^\vee$. This means that $y$ is not isolated and hence $\ker_\Z(A)^\vee$ is not a lattice. 
\end{proof}

\begin{conj}\label{AlgebraicChar} Suppose that $A$ is an $m\times n$ matrix with algebraic entries.  Let $\Lambda = \ker_\Z(A)$\begin{enumerate}
    \item If $dim(\Lambda) < n-m$, then $\Lambda^\vee $ is not a lattice. 
    \item \textcolor{blue}{There is a submodule (a $\Z$-module) $V$ of $\Lambda^\vee$ such that $dim(V) = dim(\Lambda)$ and $V$ is a integer lattice. } \textcolor{red}{this is the submodule of $\Lambda^\vee$ which behaves like the ``lattice'' dual we intuitively want when we have a lattice I think. That is what I'm trying to describe here.}
\end{enumerate}
\end{conj}

\subsection{Aribarty Real Data}
\section{Background}
\subsection{Lattice Basis/Dual Spaces}
\begin{defn} \cite{coursenotes}
 The dual of a lattice of $\Lambda$ is the set $\tilde \Lambda = \{x: xy^T \in \Z, x\in \text{span}(\Lambda), y\in \Lambda \}$.
\end{defn}
\begin{thm}\label{DualLattice}
The dual of a lattice $\Lambda = \mathcal{L}(B)$ with basis $B$ is a lattice with basis $D = B(B^TB)^{-1}$. 
\end{thm}
\begin{proof}
Let $B= (b_1,b_2,...,b_n)$. By assumption, the columns of $B$ are linearly independent. Therefore the rows of $B^T$ are linearly independent. Looking at $B^TB$, its columns must be linearly independent because the rows of $B^T$ and columns of $B$ are linearly independent. 
{\color{red} Should I say more/ be more explicit?} 
Now we show that $\text{span}(D) = \text{span}(B)$. If $y\in \text{span}(D)$, then there is a $x$ such that $Dx =y$. Then $B(B^TB)^{-1}x = y$ and $y\in \text{span}(D)$. On the other hand if $y\in \text{span}(B)$, then there is an $x$ such that $Bx = y$ and then $D(B^TB)x = Bx = y$ hence $y\in \text{span}(D)$. 
Notice that $B^T D = B^T B(B^TB)^{-1} = I$. For any $\tilde{x} = Bx \in \Lambda $ and $ Dy \in \La(D) $, $(Dy)^T(Bx) = y^Tx \in \Z$ because both $y,x \in \Z^n$, and the calculation $Dy^T = y^TD^TBx = y^T(B^TD)^Tx = y^T I x = y^Tx$. This implies that $\La(D)$ is contained in the dual of $\Lambda$. Let $v$ be the dual of $\Lambda$ with $B^Tv\in \Z^k$ and $v\in \text{span}_\R(B)$. (This exists by checking the definition of dual, this is what these next steps justify the other containment.) Therefore $v = Bw$ for some $w\in \R^n$ and $D(B^Tv) \in L(D)$ remembering that $B^Tv \in \Z^k$. Notice that $DB^Tv =DB^TBw = Bw = v $ which must be in $L(D)$. This shows that $\La(D)$ is the dual of $\Lambda$.
\end{proof}
\begin{prop}
If $\Lambda = \La(B)$, then $\tilde{\tilde{\Lambda}} = \Lambda$. 
\end{prop}
\begin{proof}
We can see that the basis are the same by a quick computation. $\tilde{\Lambda} = \La(D) = \La(B(B^TB)^{-1})$ and $\tilde{\tilde{\Lambda}} = \La( D(D^TD)^{-1}) = \La(B)$ because $D(D^TD)^{-1} = B(B^TB)^{-1} ((B(B^TB)^{-1})^TB(B^TB)^{-1})^{-1} =B(B^TB)^{-1} (((B^TB)^{-1})^T(B^TB)(B^TB)^{-1})^{-1}= B(B^TB)^{-1} (((B^TB)^{-1})^T)^{-1} = B.$
{\color{red} I feel like this could be omitted.}
\end{proof}



\subsection{$\Z$-modules and Linear Algebra}

\subsection{Commutative Algebra and Field Extensions of $\Q$}
\subsection{Number Theory}
A fact used that that every irrational number has a unique continued fraction expansion.




\subsection{Topology}
\subsection{Analysis}

\section{Tasks}
\begin{itemize}
    \item Review details and find references for dual module definition
    \item Refine Conjecture \ref{AlgebraicChar}
    \item Prove Conjecture \ref{AlgebraicChar}
    \item Verify details of conjectured algorithm to solve case 2 in general.
    \item If above is true, write algorithm
    \item Add appropriate background to make the writing self contained.
    \item Write Personal Notes and Background on $\Z$-modules, Linear Algebra, Commutative Algebra, Field extensions of $\Q$/Galois Theory.
    \item Finish Section on Lattice Theory
    \item Write section on Number Theory, Diophantine Equation solving (the basics), continued Fractions, Pell Eqauations, 
    \item Write Personal Notes on Analysis/Topology basis for the work with items about Fourier series, convergence, density, ect.
    \item Read and understand proof of Subspace Theorem
    \item Read and understand proof of Dirichlet's approximation theorem
    \item Read more about number theoretic approximation
\end{itemize}
\end{document}