\documentclass{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,mathabx,biblatex}
\usepackage{tikz-cd}
\usepackage{geometry}
\geometry{ margin=1.25in}
\linespread{1.2}
\renewcommand\qedsymbol{$\blacksquare$}
%-----------------------------------------------------------------------------------------
%-------AESTHETIC CHANGES:
\newcommand{\nl}{\bigskip \\ } %New Line with space. 
  \renewcommand{\leq}{\leqslant}
  \renewcommand{\geq}{\geqslant}
%-----------------------------------------------------------------------------------------
%-------ABBREVIATIONS:
  \newcommand{\es}[0]{\emptyset}		%  empty set.
  \newcommand{\se}[0]{\subseteq}		%  subset or equal.
  \newcommand{\ps}[0]{\subset}			%  proper subset.
%-----------------------------------------------------------------------------------------
%-------SETS OF NUMBERS:
  \newcommand{\N}[0]{\mathbb{N}}		%  Natural ##s
  \newcommand{\Z}[0]{\mathbb{Z}}		%  Integer ##s
  \newcommand{\Q}[0]{\mathbb{Q}}		%  Rational ##s
  \newcommand{\R}[0]{\mathbb{R}}		%  Real ##s
  \newcommand{\ER}[0]{\overline{\mathbb{R}}}	%  Extended Real ##s
  \newcommand{\C}[0]{\mathbb{C}}		%  Complex ##s
  \newcommand{\EC}[0]{\overline{\mathbb{C}}}	%  Extended Complex ##s
  \newcommand{\SP}[0]{\mathbb{S}}		%  Sphere
  \newcommand{\So}[0]{\SP^1}			%  1-Sphere
  \newcommand{\Sm}[0]{\mathcal S}
  \newcommand{\La}[0]{\mathcal L}
  \newcommand{\im}[0]{\text{im}}
%-----------------------------------------------------------------------------------------
%-------LOGICAL STATEMENTS:
  \newcommand{\fa}[1]{\(\forall\,#1\,\)}	%  for all ...
  \newcommand{\te}[1]{\(\exists\,#1\,\)}	%  there exists	...
  \newcommand{\then}[0]{\Longrightarrow}	%  then ...
%  \newcommand{\iff}[0]{\Longleftrightarrow}	%  if and only if ...
%-----------------------------------------------------------------------------------------

\newcommand{\gen}[1]{\langle #1 \rangle} %brackeded generator 
  \newcommand{\abs}[1]{\left\lvert#1\right\rvert}	%  Absolute Value |.|
  \newcommand{\abst}[1]{\lvert#1\rvert}			%  Absolute Value (text)
  \newcommand{\norm}[1]{\left\|#1\right\|}		%  Norm ||.||
  \newcommand{\ip}[2]{\left\langle#1,#2\right\rangle}	%  Inner Product <.,.>
  \newcommand{\ipt}[2]{\langle#1,#2\rangle}		%  Inner Product (text)
  \newcommand{\ipn}[1]{\left\langle#1,#1\right\rangle}  %  Inner Product Norm
  \newcommand{\de}[2]{\frac{d#1}{d#2}}			%  Diff.
  \newcommand{\nde}[3]{\frac{d^{#3}#1}{d#2^{#3}}} 
	%  nth order diff.
  \newcommand{\der}[1]{\frac{d}{d#1}}			%  Der.
  \newcommand{\des}[2]{\frac{d^2#1}{d#2^2}}		%  2nd order diff.
  \newcommand{\pde}[2]{\frac{\partial#1}{\partial#2}}	%  p. diff.
  \newcommand{\pdes}[2]{\frac{\partial^2#1}{\partial#2^2}}  %  2nd Order P. Diff.
  \newcommand{\npde}[3]{\frac{\partial^{#3}#1}{\partial#2^{#3}}}  %  nth Order P. Diff.
  \newcommand{\tpde}[3]{\frac{\partial^2#1}{\partial#2\,\partial#3}}  %  2* P.Der.
  \newcommand{\pder}[1]{\pde{}{#1}}			%  Partial Derivative
  \newcommand{\pders}[1]{\pdes{}{#1}}			%  Partial Derivative
  \newcommand{\tpder}[2]{\tpde{}{#1}{#2}}		%  2* Partial Derivative
  \newcommand{\defct}[3]{#1:#2\rightarrow#3}		%  Function Definition
% A couple of notes on these definitions, those with a `t' appended to
% the end are intended for use in the short math expression environments
% they get rid of the enlarging of the delimiters and make everything
% nice and compact.
%	DOCUMENT SPECIFIC NOTATION:
\newcommand{\T}{\mathcal T}		%  Tangential unit vector
  \newcommand{\B}[0]{\hat{B}}		%  Torsional unit vector
  \newcommand{\e}[1]{\hat{e}_{#1}}
  \newcommand{\X}[0]{\mathcal{X}}
  \newcommand{\y}[0]{\mathcal{y}}
    \newcommand{\per}[1]{\left(#1\right)}
  \newcommand{\D}[0]{\mathrm{D}}
  \newcommand{\LL}[0]{\mathrm{L}}
%	FORMATING:
%  \renewcommand{\qedsymbol}{\(\bigstar\)}	%  Cuter Q.E.D.
  \renewcommand{\labelenumi}{(\roman{enumi})}	%  Roman numberals good
    \newtheorem{thm}{Theorem}[section]
    \newtheorem{lem}[thm]{Lemma}
    \newtheorem{cor}[thm]{Corollary}
    \newtheorem{prop}[thm]{Proposition}
    \newtheorem{ex}[thm]{Example}
    \newtheorem{conj}[thm]{Conjecture}
  \theoremstyle{definition}
    \newtheorem{defn}[thm]{Definition}
    \newtheorem*{T0}{\(T_0\) Axiom}
    \newtheorem*{T1}{\(T_1\) Axiom}
    \newtheorem*{T2}{\(T_2\) Axiom}
    \newtheorem*{T3}{\(T_3\) Axiom}
    \newtheorem*{T35}{\(T_{3\frac{1}{2}}\) Axiom}
    \newtheorem*{T4}{\(T_4\) Axiom}
  \theoremstyle{remark}
    \newtheorem{rem}[thm]{Remark}
  \newcommand{\rlem}[1]{Lemma~\ref{#1}}
  \newcommand{\rlems}[2]{Lemmas~\ref{#1} \& \ref{#2}}
  \newcommand{\rrem}[1]{Remark~\ref{#1}}
  \newcommand{\rprop}[1]{Proposition~\ref{#1}}
  \newcommand{\rprops}[2]{Propositions~\ref{#1} \& \ref{#2}}
  \newcommand{\rthm}[1]{Theorem~\ref{#1}}
  \newcommand{\rdef}[1]{Definition~\ref{#1}}
  \newcommand{\refig}[1]{Figure~\ref{#1}}
  \newcommand{\rfig}[1]{Figure~\ref{#1}}
  \newcommand{\rcor}[1]{Corollary~\ref{#1}}
  \newcommand{\requ}[1]{Equation~\ref{#1}}
  \newcommand{\rpage}[1]{p.~\pageref{#1}}
\newcommand{\tensor}{\otimes}
%	MISC.:
  \newcommand{\topol}[0]{\mathcal{T}}

%	MEASURE THEORIC NOTATIONS:
  \newcommand{\sig}[1]{\(\sigma\)-#1}			% sigma-...
  \newcommand{\co}[0]{\mathcal{E}}			% arbitrary class of sets.
  \newcommand{\ri}[0]{\mathcal{R}}			% arbitrary ring.
  \newcommand{\sr}[0]{\mathcal{S}}			% arbitrary sigma ring.
  \newcommand{\sa}[0]{\mathfrak{M}}			% arbitrary sigma algebra.
  \newcommand{\hc}[0]{\mathcal{H}}			% arbitrary hereditary class.
  \newcommand{\di}[2]{\int#1\,d#2}			% integral of 1 wrt 2.
  \newcommand{\io}[3]{\int_#1#2\,d#3}			% integral of 2 wrt 3 over 1.
%  \usepackage{quiver}
 \addbibresource{ref.bib}

\title{Unimodular Affine Transformation}
\author{Acadia Larsen}
\begin{document}
\maketitle
\textcolor{red}{Text in red is questions/things i'm not sure about}\nl 
\textcolor{blue}{text in blue is things I am going to change and have written for my own edification.}
\section{Preliminaries for Lattices and Rational Vector Spaces }
Though out, let $V$ be a $m$ dimensional real vector space. 
 \begin{defn}
 
A \textbf{lattice} $\Lambda$ is a subset of $\R^m$ which is an additive Abelian subgroup under standard vector addition with the condition there are $k$ linearly independent vectors $b_1,...,b_k$ where $\Lambda = \left\{\sum\limits_{i=1}^k \lambda_i b_i : \lambda_i \in \Z\right\}$. The vectors $b_1,...,b_k$ for a basis for the lattice. The number of linearly independent vector $b_i$ is the rank of the lattice.  If $k=m$, then we say the lattice $\Lambda$ is full rank in $V$. 
 \end{defn}
  We write $\Lambda = \La(B)$ to denote a lattice with a basis $B = \{b_1,...,b_n\}$. A lattice is topologically discrete meaning that it has the finest topology which in which singletons are opens sets with respect to the standard topology induced by the Euclidan norm on $\R^m$. In particular, every point in a lattice is isolated, i.e. there exists a $r>0$ such that for all $x\in \Lambda$ $B_r(x) \bigcap \Lambda = \{x\}$. \nl 

A \textbf{rational vector space} $V$ of dimension $m$ is a finite dimensional real vector space with a lattice denoted by $\Lambda$ where $\Lambda$ is full rank in $V$. An element $v\in V$ is called \textbf{rational} if $nv\in \Lambda$ for $n\in \Z^+$. We say a subspace $L$ of $V$ is called \textbf{rational} if $L\cap \Lambda$ is a full rank lattice in $L$. The image of $\Lambda$ in $V /L$ is called the \textbf{projected lattice}.\cite{Baldoni_2012} \nl 

Our goal is to given a direct decomposition of $V$, the ambient space, into a rational vector space $L$ with lattice $\Lambda$ with a direct sum complement $M$, find an affine transformation that is \textbf{lattice preserving} \textcolor{blue}{write down what this means precisely} for $L$ and, depending on other options, arbitrary/orthogonal/orthonormal for $M$. In this context, $L$, $\Lambda$, and $V$ are data of the problem.  \nl 

The lattice $\Lambda$ determines the subspace $L$ and is sufficient input for the problem. Setting $L  =\text{span}_\R(\Lambda)$, this holds because $L$ is assumed to be a rational vector space, we need $L\cap \Lambda$ to be full rank in $L$ which means that $\Lambda$ has the dimension of $L$ basis vectors and hence also spans $L$. The dimension of the ambient vector space can be determined by the input data. Therefore only a lattice is needed as data to the problem. \nl 

\textcolor{blue}{here would be a good place to put some examples of inputs and results with explanations and diagrams}


% For this  problem, we expect two types of input. Case one is the user gives a list of real vectors in a lattice $B = \{b_1,..., b_N\}$ where $b_1,...,b_N \in \R^m$. The second case is when the data arises arises as the affine hull of a polytope $P = \{x\in \R^N : Ax\leq b, A\in \R^{m\times N}\}$ defined as $aff(P) = \ker_\Z(A).$

%We will work though examples of both cases. First, a list of vectors.
%Affine map, Ax=b, Ax=0 affine part?
% \begin{ex}
% Let $B = \{(1,-1)^T\}$ be the input data.
% \end{ex}
% Here $\Lambda=\mathcal L (B)$ is a rank 1 lattice. Proceeding as suggested, set $L= \text{span}_\R(\Lambda)$. The ambient vector space is $V=\R^2$. $L$ is a rational vector space by definition. $B$ can be completed to a basis of $V$ by adding the vector $(0,1)^T$ to the set. Let $M=\text{span}_\R\{(0,1)^T\}$.  So $V = L\oplus M$. Notice that $L= \ker\left( \begin{bmatrix}-1&1\end{bmatrix}\right)$, set the transformation $T= \begin{bmatrix} \end{bmatrix}$
%\begin{ex}
%Let $B = \{(1,0)^T, (1,1)^T, (-1,1)^T\}$ be the input data.
%\end{ex}
%\begin{proof}
%Let $B = \begin{bmatrix} 1 & 1 &-1 \\ 0 &1 &1
%\end{bmatrix}$ and observe $\ker_\Z(B) = \langle (2,-1,1)^T\rangle_\Z$. Set $\Lambda = \ker_\Z(B)$ is an affine subspace  %For $y\in \R^3$, $y = Ax +b$ The ambient space which should be used is $V= \R^3$. Let $x\in \ker_\Z(B)$, $Bx =\begin{pmatrix}y_1\\y_2\end{pmatrix}$.  Let $L=\langle \Lambda \rangle_\R $. Then $L\cap\ker_\Z(B) = \ker_\Z(B)$ is a full rank lattice in $L$ is a rational vector space. 


%\end{proof}
%The first case is equivalent to the second case. Let $B$ be the $m\times N$ matrix with columns $b_1,..., b_N$.\nl  

% \begin{prop}\label{caseequivalents}
% Case one is equivalent to case two
% \end{prop}
% \begin{proof}

% \end{proof}
\noindent{\large \textbf{Process Outline:}}\nl
\textbf{Step 1.} The user gives data (a lattice $\Lambda$) to the function.  Either as a list of vectors $B=\{b_1,...,b_N\}, b_i\in \R^m$ or arising from as the integer kernel from a linear system (polytope, linear system, ect), $\Lambda = \{x\in \Z^N: Ax=0\}$ for some $m\times N$ matrix $A$. %Using  Proposition \ref{caseequivalents}, the two cases are equivalent.
%We phrase everything in terms of case two with $A$ an $m\times N$ real matrix and $L = \ker_\R(A)$, $\Lambda = \ker_\Z(A)$. %, $V =\R^m$. 
\nl 
\indent \textit{Processing Data: List of Vectors $B=\{b_1,...,b_N\}$}\nl 
\textcolor{red}{Write down what this ought to be. I think you take $A =\begin{bmatrix} b_1 &b_2 & \cdots & b_N\end{bmatrix}.$ Set $\Lambda = \ker_\Z(A)$ and proceed as in the section below.}%Let $ %prob not the right thing to do. Double check when you ahve more energy 
\nl 
\indent \textit{Processing Data: Determining $\Lambda= \ker_\Z(A)$}\nl 
Data from the matrix $A$ comes in two flavors: integral (or rational, these are equivalent) and  mixed integer (real and integral).  \nl 
\indent \textit{Case I:} If $A$ is rational, one can compute the Hermite Normal Form of $A$, i.e. writing $A = U(D~0)$ where $U$ is an $m\times m$ unimodular matrix, $D$ a $m\times m$ upper triangular matrix. Assuming $N-m>0$ the last $N-m$ columns of $U$ form a basis of $\Lambda$. In this case $\Lambda$ is a lattice of rank $k=N-m$.  \nl 
\indent \textit{Case II:} If $A$ is mixed integer and has all algebraic entries, then Theorem \ref{AlgebraicEnteries} gives how to compute $\Lambda$ in this case. The rank of $\Lambda$ is $0\leq k\leq N-m$. Theorem \ref{dualNotLattice} explains inequality about the rank of $\Lambda$.   \nl %then $\Lambda he lattice is specified by a collection of $N$ vectors $B= \{b_1,...,b_N\}$ in the lattice with the possibility of $N\geq m$. {\color{red} We will show that this is a special case of case 2.}\nl 
\indent \textit{Case III:} \textcolor{blue}{If $A$ is mixed integer and has arbitrary real entries, then there is something with continued fractions which might be able to solve this. This is on my TO DO LIST.}
% \indent \textit{Case 2:} The lattice is specified by as the integer kernel from a linear system of equations i.e. $\Lambda = \{x\in \Z^n: Ax=0\}$ for some $m\times n$ matrix $A$.
% Depending on the smallest subfield of $\R$ that the entereis in $A$ are, there are different approaches for finding a lattice basis here. \nl  
% {\color{red} \indent \textit{Case 3:} The lattice is specified as integer kernel of the affine hull of a polytope. Since the affine hull of a polytope is given by it's equations being 0, we can reduce this case to case 2. }\nl 


\textbf{Step 2.} Complete a basis of $V$. That is find a basis of $M\cong V/L$ say $b_{k+1},..., b_{m}$ with the vectors having user specified properties. The user can chose the basis to be arbitrary, orthogonal, orthonormal to with respect to each other, $L$, or $\Lambda$ as appropriate. % \textcolor{blue}{remember $L = span_\R\{\Lambda\}$, not $\ker_\R(A)$.  }
\nl 
\textbf{Step 3.} Define the map $T$ as $T = (b_1,...,b_k,b_{k+1},...b_m)$. Return $ T$ as a matrix. \textcolor{blue}{At some point I need to show how this addresses the request of the function.}  \nl 




\section{Computing $\ker_\Z(A)$}\
The input for the Unimodular affine transformation function will be translated to the form a matrix $A$ defining a lattice being $\Lambda= \ker_\Z(A)$. 
\subsection{Rational/Integral Data}
In this section, we give background and prove how to 
\begin{defn}
A unimodular matrix $U$ is a square matrix with integer entries and $\det(U)=\pm 1$. %(I.e $U\in GL_n(\Z)$) 
\end{defn}
An important form of integral linear transformations is the Hermite normal form. 
\begin{defn}
The Hermite normal form of a matrix $A\in\Z^{m\times N}$ is a matrix $H$ with a $m\times m$ lower triangular matrix $D$ with strictly positive entries such that $AU = H = (D~0)$ where $U$ is a $N\times N$ unimodular matrix.
\end{defn}
\begin{lem}
If $A$ is an integral $m\times N$ matrix and $U$ is a $N\times N$ unimodular matrix, then $\La(AU) = \La(A)$. 
\end{lem}
{\color{blue}Polish --  
\begin{proof}
 Since $Ux = w$ where $w\in \Z^N$ and that $U$ is unimodular, we know that $U^{-1}$ is also unimodular, so $x = U^{-1}w$. By this fact $\La(A) = \{Ax :x\in \Z^N\} = \{AU U^{-1}w : U^{-1}w\in \Z^N \} =\{AU x : x\in \Z^N \} =\La(AU)$. 
 \end{proof}}
\begin{prop}
\begin{itemize}
    \item Interchanging columns, adding column two columns $i$ and $j$, or multiplying a column by $-1$ can be expressed by multiplication of $A$ by unimodular matrix. 
    \item The product of unimodular matrices is a unimodular. 
\end{itemize}
\end{prop}
The proof could be left as an exercise or by reference. The interesting part is being able write down the column operations. These are simply done by modifying the identity matrix and using the properties of determinants to show that the determinate is as needed. 
\begin{thm}\label{HNF}
If $A$ is an $m\times N$ integer matrix with rank $A$ being $m$, then $A$ has a Hermite normal form and $D^{-1}A$ is an integer matrix. 
\end{thm}
\begin{proof}
\textit{Sketch.}
We describe an algorithm to compute the Hermite normal form of $A$. {\color{blue} Figure out how you like to write this proof and complete it.} 
\end{proof}
{\color{red} When $A$ has rank $k<m$, the idea is to reduce the problem to the full rank case. This can be done by defining a projection operator which is one to one on the restriction and has an easy to compute inverse. To do is to write this out properly and double check the details. }

\begin{rem}
There is polynomial time algorithm to compute the Hermite Normal form of matrix $A$ with integral entries. \cite{KoppeJesusBook} 
\end{rem}
\begin{thm}\label{LatticeBasis} %check statement is right
Suppose that $A:\R^m\to \R^N$ is a linear transformation with integral entries, then the last $N-d$ columns of $U$ in the Hermite Normal form of $A$ generate $\ker_\Z (A) =\{ x\in \Z^n: Ax = 0\}$ where $d$ is the dimension of $\ker(A)$.  
\end{thm}
\begin{proof}

 Suppose we have computed the Hermite normal form, that is $AU = H$. Let $u_i$ be one of the last $d$ columns of $U$, noting that the entries of $u_i$ are integral. Then $Au_i = 0$ by this decomposition and so $u_i\in \ker_{\Z}(A)$. Let $y = U^{-1}z$ with $z\in \ker_{\Z}(A)$, we have that $AUy = AUU^{-1}z = Az = \vec{0} = (D~0)y$. So we have that $D^{-1}AUy = (I~0)y =\vec{0}$. This implies that $y = \sum\limits_{i=d+1}^n y_ie_i$ where $e_i$ is a standard basis vector. Thus $U^{-1}z =\sum\limits_{i=d+1}^n y_ie_i  $ implies $z  =\sum\limits_{i=d+1}^n y_iUe_i =\sum\limits_{i=d+1}^n y_iu_i   $ hence the last $d$ columns of $U$ form a basis of $\ker_{\Z^m}(A). $ 

\end{proof}



\begin{prop}
Let $A:\R^m \to \R^n$ be an integral linear transformation. $\ker_\Z(A) \cap \Lambda$ can be computed by computing the Hermitian Normal form of the dual of $\ker_\Z(A) \cap \Lambda$.
\end{prop}
\begin{proof}
We can commute the dual basis of $\ker_Z(A)$ and $\Lambda$. Let $B$ be the lattice basis of $\ker_\Z(A)$ and $B'$ be the lattice basis of $\Lambda$ with dual basis $C$ and $C'$ respectively.   The lattices of $\La(B)$ and $\La(B')$, then the dual of $\La(B)\cap \La(B')$ is $\La([C|C'])$. This can be checked by a similar argument to Theorem \ref{DualLattice}. Then basis for $\La(B)\cap \La(B')$ can be computed via Theorem \ref{LatticeBasis} using the matrix $[C|C']$ and taking the dual of that. 
\end{proof}



\subsection{Algebraic data}

\begin{ex}\label{DimDiff}
Let $A = \begin{bmatrix}1+\sqrt{2} & 0 & 1+\sqrt{2} & \sqrt{3} \\ 0 & 1 & -1 &1\end{bmatrix}$. Then $\ker_\Z(A) = \left\{a\begin{pmatrix} -1\\ 1\\ 1\\ 0\end{pmatrix}: a\in \Z\right\}$. 
\end{ex}
\begin{proof}
First, $\Q(\sqrt{2},\sqrt{3})\subset \R$ is a  4 dimensional $\Q$ vector space with basis elements $1,\sqrt{2},\sqrt{3},\sqrt{6}$. For any $x\in \Q(\sqrt{2},\sqrt{3})$, there are rational numbers $q_1,q_2,q_3,q_4$ such that $q_1+q_2\sqrt{2} +q_3\sqrt{3} +q_4\sqrt{6} = \begin{pmatrix}1& \sqrt{2} & \sqrt{3} & \sqrt{6} \end{pmatrix}\begin{pmatrix} q_1\\ q_2\\q_3\\q_4\end{pmatrix}$.  Let $\vec{\alpha} = \begin{pmatrix}1& \sqrt{2} & \sqrt{3} & \sqrt{6} \end{pmatrix}$. Then $Ax = 0$ with $x\in \Q^4$, gives two equations $(1+\sqrt{2}) x_1 + 0 x_2 + (1+\sqrt{2}) x_3 + \sqrt{3}x_4 = 0$ and  $0x_1 + 1 x_2 + - x_3 + 1x_4 = 0$. The first equation in $\Q(\sqrt{2},\sqrt{3})$ is \begin{align}
    (1+\sqrt{2}) x_1 + 0 x_2 + (1+\sqrt{2}) x_3 + \sqrt{3}x_4 &= 0\\ 
     \begin{pmatrix}1\\1\\0\\0\end{pmatrix} x_1 +\begin{pmatrix}0\\0\\0\\0\end{pmatrix} x_2+  \begin{pmatrix}1\\1\\0\\0\end{pmatrix} x_3+  \begin{pmatrix}0\\0\\1\\0\end{pmatrix} x_4& =\begin{pmatrix}0\\0\\0\\0\end{pmatrix} \\ 
    \begin{pmatrix}1&0&1&0\\1&0&1&0\\0&0&0&1\\0&0&0&0\end{pmatrix} x =\begin{pmatrix}0\\0\\0\\0\end{pmatrix} . 
\end{align} A similar matrix equation holds for the other equation seeing that \begin{equation}\begin{pmatrix}0&1&-1&1\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix} x =\begin{pmatrix}0\\0\\0\\0\end{pmatrix}. \end{equation} As the $x$ vector is the same in both cases we can write this as a single matrix equation \begin{equation}\label{Ex2}
    \begin{pmatrix}1&0&1&0\\1&0&1&1\\0&0&0&1\\0&0&0&0\\0&1&-1&1\\0&0&0&0\\0&0&0&0\\0&0&0&0\end{pmatrix} x=\begin{pmatrix}0\\0\\0\\0\\0\\0\\0\\0\end{pmatrix}. 
\end{equation} 
So solving $Ax=0$ for $x\in \Q^4$ is equivalent to solving the equation in line (\ref{Ex2}). This can be done with any method to solve matrix equations over a field. Take for instance Gram-Schmidt or LU-Factorization. Solving this matrix equation, we conclude that $x\in \text{span}\left\{\begin{pmatrix} -1\\ 1\\ 1\\ 0\end{pmatrix}\right\} $ in $\Q^4$. Picking $x$ such that $x\in \Z^4$, we arrive at the desired conclusion. 
\end{proof}
\begin{thm}\label{AlgebraicEnteries}
Suppose that $A$ is an $m\times n$ matrix each entry being algebraic over $\Q$. \textcolor{blue}{Then $\ker_\Z(A)$ can be computed by an equivalent rational matrix problem. }
\end{thm}
\begin{proof} 
We have that $\{x\in \Z^n : Ax = 0\} \subset \{x\in \Q^n : Ax =0\}$. There is an $a\in \Z$ such that for any  $x\in \Q^n$, $ax \in \Z^n$. Therefore if $x\in \Q^n$ and $Ax =0$, then $ax\in Z^n$ and $A(ax) = 0$. So computing $\ker_\Q(A)$ gives $\ker_\Z(A)$ too. 

Next, all the entries $a_{ij}$ of $A$ are algebraic over $\Q$, there is a polynomial such that $p(x)$ such that $p(\alpha_{ij}) \in \Q$. Let $m(x)$ be the minimal polynomial such that if $\alpha$ is a root of $p(x)$ then $\alpha$ is a root of $m(x)$. Then let $\Q(\alpha)$ be the splitting field of $m(x)$. This is a field extension of $\Q$ of degree $d$ where $d$ is the degree $m(x)$. Such a field extension of $\Q$ is a $d$ dimensional $\Q$ vector space with basis $1,\alpha_1,\dots,\alpha_{d-1}$ letting $\vec{\alpha}^T = (1,\alpha_1,...,\alpha_{d-1})$ where $\alpha_i$ are the distinct roots of $m(x)$. Then for $y\in \Q(\alpha)$, we have $y =\vec{\alpha}^T \begin{pmatrix}
y_1\\ y_2\\ \vdots \\ y_d 
\end{pmatrix} = \vec{\alpha}^T \vec{y}$. In particular for entries $a_{ij} $ in $A$, we can express the entry as  $a_{ij}=\vec{\alpha}^T \vec{a_{ij}} $

Now computing $Ax =0$ for $x\in \Q^n$. For $1\leq i\leq m$, $Ax=0$ implies \begin{equation}
    \sum_{j=1}^m a_{ij} x_i = \sum_{j=1}^m \vec{\alpha}^T \vec{a_{ij}} x_i  = \vec{\alpha}^T\sum_{j=1}^m  \vec{a_{ij}} x_i  =\vec{\alpha}^T \vec{0}.
\end{equation} We can use left cancellation and then solve the equivalent problem \begin{equation}
     \sum_{j=1}^m \vec{a_{ij}} x_i = \begin{bmatrix} \vec{a_{i1}} & \vec{a_{i2}} & \cdots & \vec{a_{in}} \end{bmatrix} x=  \vec{0}.
\end{equation}  Let $\vec{A}$ be the matrix with entry $ij$ being $\vec{a_{ij}}$. Then solving   $\vec{A} x  =  \begin{pmatrix}\vec{0} \\ \vdots \\ \vec{0}
\end{pmatrix}$ with $x\in \Q^n$ gives a solution to the original problem of $Ax = 0$ with $x\in\Z^n$. The problem  $\vec A x = 0$ can be solved by any number of matrix solving algorithms. Therefore finding $\ker_\Q(\vec{A})$ gives $\ker_\Z(A).$


\end{proof}
\textcolor{blue}{From 11.10.2022, I will worry about making the statement of Theorem \ref{AlgebraicEnteries} precise later.}


\subsection{Arbitrary Real Data}
\textcolor{blue}{TBD}
% \begin{conj}
%     Let $A$ be a real $m\times n$ matrix. If $\ker_\Z(A)$  is non-trivial, \textcolor{red}{then $\ker_\Z(A)$ can be determined (estimated) in finite time. }
% \end{conj}
% \textcolor{blue}{I'm sure there are caveats and more details. This is the spirit of what I am trying to prove right now. That is find a method that allows me to determine the $\ker_\Z(A)$ in finite time. Step one is how to compute the kernel. The second step is to figure out of way to how to stop any such algorithm. The process will work in two steps. The first step is to find an approximate solution to $Ax =0$. The task is to find $x_k\in \Q^n$ such that $||Ax_k ||$  is small, $A_kx_n =0$ where $A_k$ is a rational approximation of $A$.  Though some iterative magic, there are conditions in which a suitable $x_k$ is found implies that $kx_k\in \ker_\Z(A)$ for some $k\in \Z$.  } \textcolor{red}{ As each approximate solution is found, we need to find directions $y_k\in \Z^n$ such that $y_k^Tx_k=0$ and $y_k^T = \hat A_n^T z$ with $z \in \Z^{n+m}$. Such ``dense'' directions should approximate a dense direction $\hat A^Tz$ giving which should provide proof of dimension. Alternative, in the dual module, I think finding invariant subspace might also work as a proxy for dimension because no. invariant modules  should be the same as the number dimension. Point is there is something in the dual module of $\ker_\Z(A)$ which should allow us to confirm dimension and halt the process in finite time? no. I think this is wrong but I'm going to leave it here. The question that I'm getting at is integral dependence of two irrational numbers decidable, and I think the answer is no but I don't have a proof. Maybe the dual module stuff can be used as a halting condition for the approximation is good enough (but there are examples which it is the worse possible). More investigation is needed. }  

% To start, we recall facts about continued fractions. They represent ``fast'' converging sequences of rational numbers to real numbers and are easily represented as computer data. 
% \begin{defn}
%  A \textbf{continued fraction} of a real number $x$ is a sequence $[a_1;a_2,a_3,\cdots] = a_0 +\cfrac{1}{a_1 + \cfrac{1}{a_2 +\cfrac{1}{a_3+\dots }}}$
% \end{defn}
% \begin{defn}
%  The \textbf{convergent} of a continued fraction is $\frac{p_k}{q_k} =[a_1;a_2,a_3,\cdots, a_k]$.
% \end{defn}
% One can show the following relations for $k\geq 1$ with defining $p_{-1} =0$, $q_{-1}=1$ and $p_0 =1$ and $q_0$ corresponding the 0 and $\infty$
% \begin{equation}
%     \frac{p_k}{q_k}- \frac{p_{k-1}}{q_{k-1}} =\frac{(-1)^{k}}{q_kq_{k-1}}.
% \end{equation}
% An other important fact about continued fractions is the following. 
% \begin{thm}
% Every real number has a unique continued fraction expansion.
% \end{thm}
% Furthermore we can establish some bounds with respect to convergent. 
% \begin{thm}
% Let $x$ be a real number and suppose that $\frac{p_k}{q_k}$ is the $k$th convergent of $x$. Then $\frac{1}{q_{k+1}}<|q_kx -p_k|<\frac{1}{q_k}$.
% \end{thm}
% We will recall more facts about convergents and continued fractions as needed. 
% \begin{defn}
%  The $k^{th}$ \textbf{convergent matrix of $A$} $A_k$ is an $m\times n$ matrix with entry $ij$ being the $k$th convergent of entry $a_{ij}$ in $A$. The $k^{th}$ \textbf{error matrix of $A$} $E_k$ is an $m\times n$ matrix with $ij$ being $\frac{(-1)^k}{q_kq_{k+1}}$ where $q_k$ and $q_{k+1}$ are the denominators of the $k$ and $k+1$ convergant of entry $a_{ij}$ in $A$. 
% \end{defn}
% Alternatively, we could define $E_k = A_{k+1}-A_{k} $. This is equivalent to the definition given by the properties of partial fractions. 
% The following lemma give a relationship between the kernel of the $k$th error and the kernel of $k+1$ convergant matrix. 
% \begin{lem}\label{ErrorEquivlance}
% Suppose that $x \in \ker_\Q(A_k)$. We have that $x\in \ker_\Q(A_{k+1})$  if and only if $x\in \ker_\Q(E_{k})$. 
% \end{lem}
% \begin{proof}
% A quick computation gives that for $x\in \ker_Q(A_k)$, 
% \begin{align}
%     A_{k+1}x &= A_{k+1}x-A_{k}x\\ 
%     &=(A_{k+1}-A_k)x\\
%     &= E_k x.
% \end{align}
% The result immediately follows. 
% \end{proof}
% \begin{lem}
% Suppose there is an nonnegative integer $k$ such that $x\in \ker_{\Q}(A_{k+m})$ for all $m\geq 0$. Then $Ax = 0$. 
% \end{lem}
% \begin{proof}
% Note that $A- A_{k} \approx E_k$ with respect to the norm induced by these matrices by the properties of continued fractions. So $Ax = Ax -A_{k+m}x = (A-A_{k+m})x.$ Computing the limit, $\lim_{k\to \infty}(A-A_{k+m})x  = \lim_{\k\to \infty } E_k x= 0 $ by Lemma \ref{ErrorEquivlance}. 
% \end{proof}
% \begin{lem}
% Suppose that $x \in \ker_\Q(A_k)$ and $y \in \ker_\Q(A_{k+1})$. If $x=\lambda y$ and  $E_{n+1}x = 0$, then $x\in \ker_\Q(A_{k+m})$. %$A_{n+2}x$. First $A_{n+1}(x-y) = E_{k}y = E_{k}x$ by assumption.  For all $m\geq 0$, if $x\in \ker_\Q(A_{k+1})$, then $x\in \ker_Q(A_{k+m})$. 
% \end{lem}
% \begin{proof} 
% We want to show the condition imply that $A_{k+m}x =0$ We have that $A_{k+2}x=0$ computing $0=(E_{k+2} - E_{k+2})x = E_{k+2} x + (A_{k+3}- A_{k+2}))x$

% Suppose that $x \in \ker_\Q(A_k)$ and $x\in \ker_\Q(A_{k+1})$. By Lemma \ref{ErrorEquivlance}, $x\in \ker_\Q(E_k)$. We compute the error $E_{k+1}x$. We have \begin{align}
%     E_{k+1}x =&y \\
%     E_{k+1}x + A_{k+1}x - A_{k+1}x &=y \\
%     (E_{k+1}+ A_{k+1})x &= y+ A_{k+1}x\\
%     &= A_{k+2}x - A_{k_1}x \\
%     &=A_{k+2}x
    
% \end{align}
%\end{proof}
%if you had enough time 
\section{Structure of $\ker_\Z(A)$ with real data}
In example \ref{DimDiff} we noticed that $\ker_\Z(A)$ had rank $1$ and hence is a 1 dimensional real vector space. $\ker_\R(A)$ has two dimension. What causes this difference in dimension?  The answer lies in the dual of the $\ker_\Z(A)$ as a $\Z$-module. 
\begin{defn}
The dual of a lattice $\Lambda$ (as a $\Z$-module) is the set $\Lambda^\vee = \{ y\in \R^n: y^Tx \in \Z ,\forall x \in \Lambda\} $. %\textcolor{red}{I haven't checked the details on this thoroughly, i.e. revisited textbooks ect} %Should this be the correct language here? I think so because this should be the space of linear functionals on $\Lambda$ which preserve the $\Z$-module property. I have not double checked defintions
\end{defn}
In this section, what types of data can we expect this difference in expected dimension by the dual to $\Lambda$. % we explore the difference 
\subsection{Lattices of Full Rank}
\begin{prop}
If $A$ and $m$ by $N$ matrix with rational entries and rank $N$, then $\Lambda= \ker_\Z(A)$ is a rank $N-m$ lattice.
\end{prop}
This follow from computing the Hermite Normal form of $A$. 
\begin{prop}
If $A$ and $m$ by $N$ matrix with rational entries and let  $\Lambda= \ker_\Z(A)$, then $\Lambda^\vee$ is \textcolor{red}{correct statement about the dual here, it should be a lattice but I need to double check details}%a rank $m$ lattice. %provide proof
\end{prop}
% \begin{proof}
% This follows from computing the Hermite Normal form of $A$. This immediately gives that $dim(\ker_\Z(A)) = n-m = dim(\ker_\R(A))$. 
% \end{proof}

%\begin{thm}
%$\Lambda$ is a full rank lattice if and only if $\tilde \Lambda$ is a full rank lattice. 
%\end{thm}
%This should follows from Theorem 4.2 and prop 4.3. 
\subsection{Difference in dimension}
For $A$ in Example \ref{DimDiff}, we have that $dim(\ker_\R(A))=2$ but $dim(\ker_\Z(A))=1$. We now explain this difference in dimension. 
%Here the span of the basis vectors lie in $\R^n$. It is possible that there is a sequence $(y_n)\subseteq \tilde \Lambda$ that converges in the Eulcidan metric in $\R^n$. If such a sequence exists, then $\tilde \Lambda$ would not be a lattice because $(y_n)\to y$ and $y$ would not be an isolated point.  Furthermore, $(y_n)^Tx \in\Z $
%for all $ x\in \Lambda$ so $y^Tx \in \Z$ (strongly convergence implies weak convergence). We would $y \in \tilde{\Lambda}$. There is a trick that we can use in terms of formulating the problem to help insure that $y\in \tilde \Lambda$ which we will see in the form of an example.  %This means that $y\in \tilde{\Lambda}$ as $y \in span_\Z(\Lambda)$ by convergence. % \begin{thm}
% A lattice $\Lambda$ is full rank if and only if $\tilde \Lambda$ is full rank. 
% \end{thm}
% \begin{proof}
% ($\implies$) Suppose that $\Lamdda$ is a full rank lattice. 
% \end{proof}



% In Example \ref{DimDiff}, $\Lambda= \ker_\Z(A)$ is not a full rank lattice as since $dim(\ker_\Z(A)) < dim(\ker_\R(A))$. In the dual of $\Lambda$ as a $\Z$ module, there is a point which is not isolated meaning that the  the rowspan of $A$ is dense in some subspace of $\R^4$. This density means that the topological properties of a lattice are no longer satisfied. In the following example, we shall explicit show the violation that in the lattice dual, there is a subspace that is dense in $\R^4$ 

\begin{ex}
Let $A = \begin{bmatrix}1+\sqrt{2} & 0 & 1+\sqrt{2} & \sqrt{3} \\ 0 & 1 & -1 &1\end{bmatrix}$. Define $\hat A = \begin{pmatrix}
A \\ I_4
 \end{pmatrix}$. Let $\Lambda =  \ker_\Z(A)$ . Then $\Lambda^\vee$ is not a lattice.
\end{ex}
\begin{proof}

We will find a infinite sequence $\{z_n\}_{n=1}^\infty$ with $z_n\in \Z^6$ such that $z_n\hat A$ converges with respect to the Euclidean norm and $z_n$ is distinct form $z_m$ provided $m\neq n$. Let $x\in \Lambda$, then  $\hat Ax = \begin{pmatrix}0&0&-a&a&a&0\end{pmatrix}^T$ and $z =\begin{pmatrix}\zeta_1&\zeta_2&\zeta_3&\zeta_4&\zeta_5&\zeta_6\end{pmatrix}^T \in \Z^6$ so $z\hat A^T x = -a(\zeta_3+\zeta_4+\zeta_5)\in \Z$ so by construction $(z_n\hat A)^T = y_n\in \Lambda^\vee$. Now if $ \lim\limits_{n\to \infty} y_n= y$, it follows that $y \in \Lambda^\vee$. With the conditions put on $y$, this will let us show that $y$ is not isolated in $\Lambda^\vee$ meaning that $ \ker_\Z(A)^\vee$ cannot be a lattice.  %This will imply that $\lim\limits_{n\to \infty} \hat A^T z_n = y \in rowspan_\R(A)$. By adding the guarantee that $z_n\hat A^Tx =0$ for all $x\in \Lambda$, this guarantees that $y^Tx=0$, so $y\in \Lambda^\vee$. 


%Finding such a $y$ gives that $y$ is not isolated in the $rowspan_\R(A)$ 
We start by computing $\hat A^Tz$ for $z\in \Z^6$,
\begin{align}
    \begin{bmatrix}
    1+\sqrt{2} &0 & 1& 0 &0&0 \\ 
    0 &1 & 0& 1 &0&0 \\
    1+\sqrt{2} &-1 & 0& 0 &1&0 \\
    \sqrt{3} &1 & 0& 0 &0&1 
    \end{bmatrix}\begin{pmatrix}
    \zeta_1\\\zeta_2\\\zeta_3\\\zeta_4\\\zeta_5\\\zeta_6
    \end{pmatrix}&= \begin{pmatrix}
    (1+\sqrt{2})\zeta_1 +\zeta_3 \\ 
    \zeta_2 +\zeta_4\\
     (1+\sqrt{2})\zeta_1 -\zeta_2+\zeta_5 \\
          \sqrt{3}\zeta_1 +\zeta_2+\zeta_6
    \end{pmatrix}.
\end{align}
Consider the sequences of convergents of the partial fraction decomposition of $1+\sqrt{2}$. Define these as $\{\frac{p_n}{q_n}\}_{n=1}^\infty$. Because this is a sequence of convertenets, it gives the bound $|(1+\sqrt{2})q_n - p_n|< \frac{1}{q_n}$. 
We can pick a sequence of integers $r_n$ such that $|\sqrt{3}q_n -r_n|<1$. Now  define $z_n = \begin{pmatrix}
q_n & 1& -p_n & 1 & -p_n+1 & -r_n-1 
\end{pmatrix}^T.$ 


 Computing the norm, \begin{align}
     ||y_n|| = ||(z_n)^T\hat A||^2  &= ((1+\sqrt{2})q_n - p_n)^2+ (1-1)^2 +(1+\sqrt{2})q_n - 1- p_n+1)^2  \nonumber\\ &+ (\sqrt{3}q_n +1-r_n-1)^2< 2q_n^{-2}+1.  
 \end{align}Thus the sequence of norms is bounded above by $3$ because $|q_n|\geq 1$. We also know that because $1+\sqrt{2}$ and $\sqrt{3}$ are irrational,  $0<|(1+\sqrt{2})q_n - p_n|$ and $0<|\sqrt{3}q_n -r_n| $. So $0<||y_n||^2 < 2q_n^{-2}+1\leq 3$ is a bounded sequence. Because of this boundedness, there is a convergent subsequence of $y_n$ say which converges to some element $y_k \to y\in \Lambda^\vee$. 

%Notice since $\ker_\Z(A) = \{ n\begin{pmatrix}
%-1 & 1 &1 &0
%\end{pmatrix}^T:n\in \Z\}$ that $y_k^Tx =0$ by our choice of $z_n$. Because $rowspan_\R(A)$ is a closed set with respect to the euclidean norm, $y\in rowspan_\R(A)$ and too $y^Tx =0$. Lastly, 
We note by choosing a sequence of convergents it follows that $|(1+\sqrt{2})q_n +p_n|>|(1+\sqrt{2})q_{n+1} +p_{n+1}|$ for all $n$. This ensures that the sequence $y_k$ consists of distinct elements. Now for any $\epsilon>0$, the open ball of radius $\epsilon$ about $y$ $B_\epsilon(y)$ has an infinitely distinct points in $\ker_\Z(A)^\vee$. This means that $y$ is not isolated and hence $\ker_\Z(A)^\vee$ is not a lattice. 

We can specify this even further to show that $0$ is not isolated. Because $\lim\limits_{k\to \infty} (y_k)^T x= y^Tx$ and all $(y_k)^T x  \in \Z$, $y^Tx\in \Lambda^\vee$. Because $y\in \Lambda^\vee$ is a $\Z$ module, it has an additive inverse $-y$ so then $\lim\limits_{k\to \infty}(y_k-y)= 0$ and by the same argument above, this shows that $0$ is not isolated. 

%\textcolor{blue}{Professor Koppe claims an extra sentence should allow us to show 0 is not isolated. I haven't figure this out yet.}
\end{proof}
This particular example illuminates the general theory. 
% \begin{conj}\label{AlgebraicChar} Suppose that $A$ is an $m\times n$ matrix (rank $m$) with algebraic entries.  Let $\Lambda = \ker_\Z(A)$\begin{enumerate}
%     \item If $dim(\Lambda) < n-m$, then $\Lambda^\vee $ is not a lattice. 
%     \item \textcolor{blue}{There is a submodule (a $\Z$-module) $V$ of $\Lambda^\vee$ such that $dim(V) = dim(\Lambda)$ and $V$ is a integer lattice. } \textcolor{red}{this is the submodule of $\Lambda^\vee$ which behaves like the ``lattice'' dual we intuitively want when we have a lattice I think. That is what I'm trying to describe here.}
%     \textcolor{red}{We need to check invariantce wrt transformations} \textcolor{blue}{Revised: $\Lambda^\vee  \cong \R^{n-k } \oplus \Z^{k}$ where $k = dim(\Lambda)$.} 
%     %\item \textcolor{red}{If $k=0$ or $m-n$, then something special happens. I guess.}
%     \textcolor{red}{I think the over all goal that I had when writing this conjecture was to figure out something about the structure of the $\Lambda^\vee$. I think I was trying to say too much. What I was asking for was something to be invariant that just isn't. I should try to write precisely why this is wrong as well as show the revised structure conjecture. }
%     \item \textcolor{red}{$dim(\Lambda) = n-m$ if and only if $\Lambda^\vee$ is something. I suspect a statement like this must hold I'm not sure what the something is. I want to say } 
% \end{enumerate}
% \end{conj}
\newpage
\begin{thm} \label{dualNotLattice}
Suppose that $A$ is an $m\times N$ matrix with real %\textcolor{red}{(real I think works too in general)} 
entries of rank $m$.  Let $\Lambda = \ker_\Z(A)$. If $dim(\Lambda) < N-m$, then $\Lambda^\vee $ is not a lattice. 
\end{thm}
\begin{proof}
Suppose $dim(\Lambda)<N-m$. Define $\hat A = \begin{pmatrix}
A \\ I_n\end{pmatrix}$ and let $x\in \ker_\Z(A)$ and $z\in \Z^{n+m}$. We have that $z^T\hat A \in \R^n$ and that $z^T\hat A x \in \Z$  since $ \hat A x = \begin{pmatrix} 0 \\ x \end{pmatrix}\in \Z^{n+m}$. This means that  $(z^T\hat A)^T\in \Lambda^\vee$. Generically, we will let $\hat A^T z = y$ and if $z$ is indexed, then $y$ will have the same index.  Furthermore, if $A$ has rational entries, then dim$(\ker_\Z(A))= N-m$ by the Hermite Normal Form algorithm. The contraposition says, if $dim(\ker_\Z(A))  \neq N-m$, then $A$ has irrational entries. So $A$ must have at least one irrational entry. %\textcolor{blue}{this feels cheap and uninformative but makes sense logically.} \nl
Computing $\hat A^Tz=y$ with $z\in \Z^{m+n}$ with entry $a_{ij}$ being the entry row $1\leq i\leq m$ and column $1\leq j\leq n$ in $A$. So the $j$th entry $y_j$ of $y$ is $y_j = \sum\limits_{i=1}^m a_{ij} \zeta_i + \zeta_{m+j}$. Each $a_{ij}$ has a continued fraction expansion, i.e. there is a sequence of converents $a_{ij} = \lim\limits_{n\to \infty} \left(\frac{p_{n}}{q_{n}}\right)_{ij}$. 

We will now define a sequence $\{z_n\}_{n=1}^\infty\subseteq \Z^{n+m}$. Let $\zeta_{i,n}$ be the $i$th entry of $z_n$. Fixing $i$ and $n$, pick $\zeta_{i,n}$ such that $\zeta_{i,n} = \max_j\{(q_n)_{ij}\}$. Let $j'=argmax_j\{(q_n)_{ij}\}$ and define $\eta_{i,j',n} =(p_n)_{ij}$.  There are integers $\eta_{i,j,n}$ with $j\neq j'$ such that $|a_{ij}\zeta_{i,n} + \eta_{i,j,n}|< 1$. We have since $\eta_{i,j',n} =p_n^{ij}$ that $|a_{ij'}\zeta_{i,n} +\eta_{i,j',n}|< \frac{1}{\zeta_{i,n}} $.  Now define $\zeta_{m+j,n} = \sum\limits_{i=1}^m \eta_{i,j,n}.$ This construction of $z_n$ will allow us to bound the norm of $y_n$.

Now \begin{align}
    ||y_n||^2 = \sum_{j=1}^n (y_{j,n})^2  &= \sum_{j=1}^n\left(\sum_{i=1}^m a_{ij} \zeta_{i,n} + \zeta_{m+j,n}\right)^2\\
    &=\sum_{j=1}^n\left(\sum_{i=1}^m a_{ij} \zeta_{i,n} +  \sum\limits_{i=1}^m \eta_{i,j,n}\right)^2\\
    &=\sum_{j=1}^n\left(\sum_{i=1}^m a_{ij}\left( \zeta_{i,n} +  \eta_{i,j,n}\right)\right)^2\\
    &< \sum_{j=1}^n\left(m-1 +\frac{1}{\zeta_{i,n}}\right)^2 \leq (mn)^2
\end{align}
as $|\zeta_{i,n}|\geq 1$. 
Because  at least 1 $a_{ij}$ has a sequence of convergents in which the sequence of denominators is strictly increasing because it is irrational, so $y_n\neq y_{n+1}$ for all $n\geq 1$.  There is a subsequence $y_k$ of $y_n$ which converges because the norm of $||y_n||$ is bounded and is distinct. Because of the construction of $y_n,$ $y_{k}\in \Lambda^\vee$ and as this sequence is convergent $\lim\limits_{k\to\infty} y_k \to y$ for some $y\in \Lambda^\vee$. Every point of  $\Lambda^\vee$ to be a lattice, $\Lambda^\vee$ needs to have every point isolated, but $y$ is not isolated because for every $\epsilon>0$, there is a ball about $w$ which contains infinitely distinct points in the sequence $y^{(k)}$, so $\Lambda^\vee$ is not a lattice. 

We can specify this even further to show that $0$ is not isolated. Because $\lim\limits_{k\to \infty} (y_k)^T x= y^Tx$ and all $(y_k)^T x  \in \Z$, $y^Tx\in \Lambda^\vee$. Because $y\in \Lambda^\vee$ is a $\Z$ module, it has an additive inverse $-y$ so then $\lim_{k\to \infty}(y_k-y)= 0$ and by the same argument above, this shows that $0$ is not isolated. 
%nd for $j'=argmax_j\{q_n^{ij}\}$ $|a_{ij'}\zeta_{i,n} +z_{ij'}^{$

%(ii) Consider $z\in \ker_\Z(\hat A)$. We have that $\hat A^t z\neq   $ 

\end{proof}
% \subsection{Building Towards Dense Directions}
% The above proof suggests a notion of a direction $y\in \Lambda^\vee$ being ``dense'' in some sense with respect to the integer lattice $\Lambda = \ker_\Z(A)$. In particular, for all $x\in \Lambda$, there are infinitely many $\lambda \in (a,b)$ such that  $\lambda y^Tx \in \Z$. This means that $\lambda y \in \Lambda^{\vee}$ and also  $span_\R\{y\} \subseteq \overline{ \Lambda^\vee}$ hence $y$ being ``dense''. 

% \begin{ex}
% Let $A = \begin{bmatrix}1+\sqrt{2} & 0 &1+\sqrt{2} & \sqrt{3} \\ 0 &1&-1&1 
% \end{bmatrix}$. 
%  Let $\Lambda = \ker_\Z(A)$. We will show that $\Lambda^\vee  \cong \R^3 \oplus \Z$. %There is a submodule $V $ of $\Lambda^\vee$ such that:
% \begin{itemize}
%     \item $V$ is a lattice,
%     \item $V$ is saturated, i.e. $V\cap \Z^4= V$,
%     \item For any $C\in GL_2(\Q)$, if $x\in C\Lambda $, then if $y\in V$, we have that $y^Tx=0$.  ($V$ is invariant under transformation in some form), I need to make this more precise. 
% \end{itemize}
% In particular, we will show that  $V = \left\{ n \begin{pmatrix}
% 0 \\0\\0\\1 \end{pmatrix}: n\in \Z\right\}$ satisfies all of these properties.  
% \end{ex}
% Item (iii) we want something like if $5\Z \in \Lambda$ iff $\frac{1}{5}\Z \in \Lambda^\vee$ the lattice and dual are invariant under type of translation which lets us pass integral scalars though the dual.   
% \begin{proof}
% Steps in this proof. Let $C\in GL_2(\Q)$. First, find $\ker_\Z(CA)$ is a 1 dim subspace. 
% To satisfy lattice properties, $y^Tx= (z^T\hat A) x$, act $\hat A$ on by $C$  as $\hat A = \begin{bmatrix} C A \\ I_4\end{bmatrix},$ so $\hat A ^T = \begin{bmatrix} (CA)^{T} & I_4\end{bmatrix}$. We need to which means that $C^{-T}$ to act on some subspace of $\Z^6$ that allows the $y^Tx =0$ for the correct $y^Tx$ 

% First, we start by considering $\ker_\Z(A)$



% \end{proof}

Now we know the dual module of $\Lambda = \ker_\Z(A)$ is not a lattice. What is the structure of $\Lambda^\vee$ as a $\Z$-module? 
\begin{ex}
Let $A = \begin{bmatrix}1+\sqrt{2} & 0 & 1+\sqrt{2} & \sqrt{3} \\ 0 & 1 & -1 &1\end{bmatrix}$. \\ We claim that $ \ker_\Z(A)^\vee \cong  \langle (1,1,0,0)^T,(1,0,1,0)^T,(1,0,0,1)^T\rangle_\R \oplus \Z$.
\end{ex}
\begin{proof}

\end{proof}
% \begin{defn}
%  A non-zero vector $y\in \Lambda^\vee$ is called a \textbf{dense direction} if there is an interval $(a,b)$ such that for any $c\in(a,b)$ and for any $x\in \Lambda$ such that $cy^Tx \in \Z$.  
% \end{defn} %This is like an eigenvalue discrete version or module esque 
%czAx 
\subsection{Arbitrary Real Data}
\textcolor{blue}{Pass}
\section{Background}
\subsection{Lattice Basis/Dual Spaces}
\begin{defn} \cite{coursenotes}
 The dual of a lattice of $\Lambda$ is the set $\tilde \Lambda = \{x: xy^T \in \Z, x\in \text{span}(\Lambda), y\in \Lambda \}$.
\end{defn}
\begin{thm}\label{DualLattice}
The dual of a lattice $\Lambda = \mathcal{L}(B)$ with basis $B$ is a lattice with basis $D = B(B^TB)^{-1}$. 
\end{thm}
\begin{proof}
Let $B= (b_1,b_2,...,b_n)$. By assumption, the columns of $B$ are linearly independent. Therefore the rows of $B^T$ are linearly independent. Looking at $B^TB$, its columns must be linearly independent because the rows of $B^T$ and columns of $B$ are linearly independent. 
{\color{red} Should I say more/ be more explicit?} 
Now we show that $\text{span}(D) = \text{span}(B)$. If $y\in \text{span}(D)$, then there is a $x$ such that $Dx =y$. Then $B(B^TB)^{-1}x = y$ and $y\in \text{span}(D)$. On the other hand if $y\in \text{span}(B)$, then there is an $x$ such that $Bx = y$ and then $D(B^TB)x = Bx = y$ hence $y\in \text{span}(D)$. 
Notice that $B^T D = B^T B(B^TB)^{-1} = I$. For any $\tilde{x} = Bx \in \Lambda $ and $ Dy \in \La(D) $, $(Dy)^T(Bx) = y^Tx \in \Z$ because both $y,x \in \Z^n$, and the calculation $Dy^T = y^TD^TBx = y^T(B^TD)^Tx = y^T I x = y^Tx$. This implies that $\La(D)$ is contained in the dual of $\Lambda$. Let $v$ be the dual of $\Lambda$ with $B^Tv\in \Z^k$ and $v\in \text{span}_\R(B)$. (This exists by checking the definition of dual, this is what these next steps justify the other containment.) Therefore $v = Bw$ for some $w\in \R^n$ and $D(B^Tv) \in L(D)$ remembering that $B^Tv \in \Z^k$. Notice that $DB^Tv =DB^TBw = Bw = v $ which must be in $L(D)$. This shows that $\La(D)$ is the dual of $\Lambda$.
\end{proof}
\begin{prop}
If $\Lambda = \La(B)$, then $\tilde{\tilde{\Lambda}} = \Lambda$. 
\end{prop}
\begin{proof}
We can see that the basis are the same by a quick computation. $\tilde{\Lambda} = \La(D) = \La(B(B^TB)^{-1})$ and $\tilde{\tilde{\Lambda}} = \La( D(D^TD)^{-1}) = \La(B)$ because $D(D^TD)^{-1} = B(B^TB)^{-1} ((B(B^TB)^{-1})^TB(B^TB)^{-1})^{-1} =B(B^TB)^{-1} (((B^TB)^{-1})^T(B^TB)(B^TB)^{-1})^{-1}= B(B^TB)^{-1} (((B^TB)^{-1})^T)^{-1} = B.$
{\color{red} I feel like this could be omitted.}
\end{proof}





\section{Tasks}
\subsection{Reading Course Tasks}
\begin{itemize}
    \item Finish writing proofs and examples section 1,2, 3.1
    \item Find references for dual module definitions
    \item Edit writing so it is more readable for future me and others. 
    \item Program 
    \item Figure out what the hell went wrong with my conjecture. write about why it is wrong somewhere (personal notes)?
    \item Conjectured algorithm is false, try something else. 
    \item Add appropriate background to make the writing more self contained.
    \item write more about what makes this an affine transformation and what should make it unimodular(I guess I should normalize the matrix by the det.)
\end{itemize}

\subsection{Towards a QUAL tasks}
Try to knock of a subsections worth a week
\begin{itemize}
    \item Write Personal Notes and Background on $\Z$-modules, Linear Algebra, Commutative Algebra, Field extensions of $\Q$/Galois Theory.
    \item Finish Section on Lattice Theory
    \item Write section on Number Theory, Diophantine Equation solving (the basics), continued Fractions, Pell Eqauations, 
    \item Write Personal Notes on Analysis/Topology basis for the work with items about Fourier series, convergence, density, ect.
    \item Write Presonal Notes about geometric problems defitions to this work (affine spaces adn algebraic relations). 
    \item Read and understand proof of Subspace Theorem
    \item Read and understand proof of Dirichlet's approximation theorem
    \item Read more about number theoretic approximation
    \item Read more about the geometry of numbers, take notes
    \item Identify theorems, ect that are important. 
    \item Finish reading CH2 of Jesus Book
\end{itemize}
\end{document}